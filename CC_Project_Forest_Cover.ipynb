{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CC Project - Forest Cover.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNz1XnY0s0MzWfpzE33QOkl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/litkm/DL-with-DF-Codecademy-/blob/main/CC_Project_Forest_Cover.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNIkwofS3PNl",
        "outputId": "a8750bb8-7dd4-4fcd-ca23-95429c0acb5a"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n",
        "dataset = '/content/drive/MyDrive/CC-Project/cover_data.csv'\r\n",
        "dataset = pd.read_csv(dataset)\r\n",
        "\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2pRhFSz4Geo",
        "outputId": "a4098b90-8618-497e-b271-347ab6826680"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\r\n",
        "from sklearn.preprocessing import Normalizer\r\n",
        "from sklearn.compose import ColumnTransformer\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, InputLayer\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "import numpy as np\r\n",
        "from keras.layers import Dropout\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "\r\n",
        "x = dataset.iloc[:,0:54]\r\n",
        "y = dataset.iloc[:,-1] \r\n",
        "\r\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\r\n",
        "\r\n",
        "columns_for_standard = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points']\r\n",
        "\r\n",
        "ct = ColumnTransformer([('numeric', StandardScaler(), columns_for_standard)])\r\n",
        "\r\n",
        "X_train = ct.fit_transform(X_train) \r\n",
        "X_test = ct.transform(X_test)\r\n",
        "\r\n",
        "le = LabelEncoder()\r\n",
        "Y_train = le.fit_transform(Y_train.astype(str))\r\n",
        "Y_test = le.transform(Y_test.astype(str))\r\n",
        "\r\n",
        "Y_train = to_categorical(Y_train)\r\n",
        "Y_test = to_categorical(Y_test)\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(InputLayer(input_shape=(X_train.shape[1],)))\r\n",
        "model.add(Dense(24, activation='relu'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "\r\n",
        "model.add(Dense(12, activation='relu'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "\r\n",
        "model.add(Dense(10, activation='relu'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(Dropout(0.2))\r\n",
        "\r\n",
        "model.add(Dense(7, activation='softmax'))\r\n",
        "\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "\r\n",
        "model.fit(X_train, Y_train, epochs=35, batch_size=32, verbose=1, validation_data=(X_test, Y_test))\r\n",
        "\r\n",
        "loss, acc = model.evaluate(X_test, Y_test, verbose=0)\r\n",
        "print(\"Loss:\", loss, \"Accuracy:\", acc)\r\n",
        "\r\n",
        "y_estimate = model.predict(X_test, verbose=0)\r\n",
        "y_estimate = np.argmax(y_estimate, axis=1)\r\n",
        "y_true = np.argmax(Y_test, axis=1)\r\n",
        "print(classification_report(y_true, y_estimate))\r\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "12710/12710 [==============================] - 57s 4ms/step - loss: 0.9167 - accuracy: 0.6410 - val_loss: 0.6565 - val_accuracy: 0.7225\n",
            "Epoch 2/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.7144 - accuracy: 0.6998 - val_loss: 0.6341 - val_accuracy: 0.7281\n",
            "Epoch 3/35\n",
            "12710/12710 [==============================] - 57s 4ms/step - loss: 0.6912 - accuracy: 0.7070 - val_loss: 0.6267 - val_accuracy: 0.7311\n",
            "Epoch 4/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6843 - accuracy: 0.7110 - val_loss: 0.6150 - val_accuracy: 0.7366\n",
            "Epoch 5/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6758 - accuracy: 0.7148 - val_loss: 0.6093 - val_accuracy: 0.7387\n",
            "Epoch 6/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6718 - accuracy: 0.7159 - val_loss: 0.6094 - val_accuracy: 0.7383\n",
            "Epoch 7/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6680 - accuracy: 0.7173 - val_loss: 0.6046 - val_accuracy: 0.7414\n",
            "Epoch 8/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6646 - accuracy: 0.7181 - val_loss: 0.6032 - val_accuracy: 0.7400\n",
            "Epoch 9/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6627 - accuracy: 0.7193 - val_loss: 0.6023 - val_accuracy: 0.7392\n",
            "Epoch 10/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6619 - accuracy: 0.7195 - val_loss: 0.5972 - val_accuracy: 0.7438\n",
            "Epoch 11/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6615 - accuracy: 0.7204 - val_loss: 0.5975 - val_accuracy: 0.7434\n",
            "Epoch 12/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6579 - accuracy: 0.7216 - val_loss: 0.5978 - val_accuracy: 0.7430\n",
            "Epoch 13/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6580 - accuracy: 0.7201 - val_loss: 0.5964 - val_accuracy: 0.7433\n",
            "Epoch 14/35\n",
            "12710/12710 [==============================] - 57s 4ms/step - loss: 0.6583 - accuracy: 0.7217 - val_loss: 0.5951 - val_accuracy: 0.7438\n",
            "Epoch 15/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6552 - accuracy: 0.7228 - val_loss: 0.5929 - val_accuracy: 0.7462\n",
            "Epoch 16/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6544 - accuracy: 0.7225 - val_loss: 0.5909 - val_accuracy: 0.7457\n",
            "Epoch 17/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6527 - accuracy: 0.7237 - val_loss: 0.5896 - val_accuracy: 0.7471\n",
            "Epoch 18/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6539 - accuracy: 0.7242 - val_loss: 0.5929 - val_accuracy: 0.7464\n",
            "Epoch 19/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6540 - accuracy: 0.7225 - val_loss: 0.5936 - val_accuracy: 0.7446\n",
            "Epoch 20/35\n",
            "12710/12710 [==============================] - 57s 4ms/step - loss: 0.6535 - accuracy: 0.7231 - val_loss: 0.5901 - val_accuracy: 0.7478\n",
            "Epoch 21/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6502 - accuracy: 0.7253 - val_loss: 0.5890 - val_accuracy: 0.7474\n",
            "Epoch 22/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6519 - accuracy: 0.7252 - val_loss: 0.5883 - val_accuracy: 0.7471\n",
            "Epoch 23/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6495 - accuracy: 0.7253 - val_loss: 0.5963 - val_accuracy: 0.7425\n",
            "Epoch 24/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6514 - accuracy: 0.7250 - val_loss: 0.5886 - val_accuracy: 0.7468\n",
            "Epoch 25/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6509 - accuracy: 0.7263 - val_loss: 0.5884 - val_accuracy: 0.7466\n",
            "Epoch 26/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6515 - accuracy: 0.7263 - val_loss: 0.5876 - val_accuracy: 0.7467\n",
            "Epoch 27/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6497 - accuracy: 0.7261 - val_loss: 0.5893 - val_accuracy: 0.7459\n",
            "Epoch 28/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6478 - accuracy: 0.7267 - val_loss: 0.5894 - val_accuracy: 0.7457\n",
            "Epoch 29/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6494 - accuracy: 0.7253 - val_loss: 0.5886 - val_accuracy: 0.7457\n",
            "Epoch 30/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6479 - accuracy: 0.7279 - val_loss: 0.5865 - val_accuracy: 0.7480\n",
            "Epoch 31/35\n",
            "12710/12710 [==============================] - 57s 4ms/step - loss: 0.6487 - accuracy: 0.7272 - val_loss: 0.5885 - val_accuracy: 0.7488\n",
            "Epoch 32/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6525 - accuracy: 0.7256 - val_loss: 0.5864 - val_accuracy: 0.7475\n",
            "Epoch 33/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6519 - accuracy: 0.7260 - val_loss: 0.5874 - val_accuracy: 0.7484\n",
            "Epoch 34/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6488 - accuracy: 0.7274 - val_loss: 0.5848 - val_accuracy: 0.7489\n",
            "Epoch 35/35\n",
            "12710/12710 [==============================] - 56s 4ms/step - loss: 0.6472 - accuracy: 0.7278 - val_loss: 0.5887 - val_accuracy: 0.7483\n",
            "Loss: 0.5886740684509277 Accuracy: 0.7483304738998413\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.73      0.74     63498\n",
            "           1       0.76      0.84      0.80     85198\n",
            "           2       0.65      0.79      0.72     10581\n",
            "           3       0.86      0.01      0.01       822\n",
            "           4       0.78      0.17      0.28      2850\n",
            "           5       0.52      0.17      0.25      5229\n",
            "           6       0.88      0.45      0.60      6126\n",
            "\n",
            "    accuracy                           0.75    174304\n",
            "   macro avg       0.74      0.45      0.49    174304\n",
            "weighted avg       0.75      0.75      0.74    174304\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}